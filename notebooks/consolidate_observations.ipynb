{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf95cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynhm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461b850",
   "metadata": {},
   "source": [
    "### define the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759528db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['01473000', '05431486','09112500','14015000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = pl.Path('../NHM_extractions/20230110_pois_haj/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b0b6e",
   "metadata": {},
   "source": [
    "### make observations dirs in each extraction directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13700147",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm in all_models:\n",
    "    if not (rootdir / cm / 'observation_data').exists():\n",
    "        (rootdir / cm / 'observation_data').mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725e3b1",
   "metadata": {},
   "source": [
    "### now grab all the `nhm_ids` from the `myparam.param` file for each cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_ids = dict(zip(all_models, \n",
    "        [pynhm.PrmsParameters.load(rootdir / cm / 'myparam.param').parameters['nhm_id'] for cm in all_models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716290d",
   "metadata": {},
   "source": [
    "### assign `wkdir` to indicate where the raw CONUS netCDF files live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3bc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdir = pl.Path('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu = pd.read_csv('../Supporting_information/target_and_output_vars_table.csv', index_col=0)\n",
    "lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in wkdir.glob('*.nc')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0538e98",
   "metadata": {},
   "source": [
    "### Handle the AET parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "AET_all = xr.open_dataset(wkdir / 'baseline_AET_v11.nc')\n",
    "AET_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12329a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm, c_ids in nhm_ids.items():\n",
    "    c_da = AET_all.sel(nhru=c_ids)\n",
    "    c_da[['aet_max','aet_min']].to_netcdf(rootdir / cm / 'observation_data' / f'AET_monthly.nc')\n",
    "    c_da.groupby('time.month').mean().to_netcdf(rootdir / cm / 'observation_data' / f'AET_mean_monthly.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909c8bc",
   "metadata": {},
   "source": [
    "###  runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d625a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_all = xr.open_dataset(wkdir / 'baseline_RUN_v11.nc')\n",
    "RUN_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e207c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm, c_ids in nhm_ids.items():\n",
    "    c_da = RUN_all.sel(nhru=c_ids, time=slice('1982-01-01','2010-01-01'))\n",
    "    c_da[['runoff_mwbm','runoff_min', 'runoff_max']].to_netcdf(rootdir / cm / 'observation_data' / f'RUN_monthly.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6b98ea",
   "metadata": {},
   "source": [
    "### recharge annual\n",
    "### QUESTION - should these really be summed???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCH_all = xr.open_dataset(wkdir / 'baseline_RCH_v11.nc')\n",
    "RCH_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm, c_ids in nhm_ids.items():\n",
    "    c_da = RCH_all.sel(nhru=c_ids)\n",
    "    c_da[['recharge_min_norm','recharge_max_norm']].resample(time='1Y').sum().to_netcdf(rootdir / cm / 'observation_data' / f'RCH_annual.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18be26",
   "metadata": {},
   "source": [
    "### soil moisture --- annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0012ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOM_ann_all = xr.open_dataset(wkdir / 'baseline_SOMann_v11.nc')\n",
    "SOM_ann_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm, c_ids in nhm_ids.items():\n",
    "    c_da = SOM_ann_all.sel(nhru=c_ids)\n",
    "    c_da[['soil_moist_min_norm','soil_moist_max_norm']].to_netcdf(rootdir / cm / 'observation_data' / f'Soil_Moisture_annual.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587903ae",
   "metadata": {},
   "source": [
    "### soil moisture --- monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269da33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOM_mon_all = xr.open_dataset(wkdir / 'baseline_SOMann_v11.nc')\n",
    "SOM_mon_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm, c_ids in nhm_ids.items():\n",
    "    c_da = SOM_mon_all.sel(nhru=c_ids)\n",
    "    c_da[['soil_moist_min_norm','soil_moist_max_norm']].to_netcdf(rootdir / cm / 'observation_data' / f'Soil_Moisture_monthly.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a16f8",
   "metadata": {},
   "source": [
    "### notes from Parker about snow cover calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(filename, f_vars, start_date, end_date):\n",
    "#     # This routine assumes dimension nhru exists and variable nhm_id exists\n",
    "#     df = xr.open_dataset(filename)\n",
    "#     # NOTE: Next line needed if nhm_id variable exists in netcdf file\n",
    "#     df = df.assign_coords(nhru=df.nhm_id)\n",
    "#     if isinstance(f_vars, list):\n",
    "#         df = df[f_vars].sel(time=slice(start_date, end_date))\n",
    "#     else:\n",
    "#         df = df[[f_vars]].sel(time=slice(start_date, end_date))\n",
    "#     return df\n",
    "# baseline_df = fbc.get_dataset(baseline_file, [sca_var, ci_var, 'nhru'], st_date, en_date)\n",
    "#     # TODO: 2021-05-05 PAN - Need to check we got the date range we requested\n",
    "#     if remove_ja:\n",
    "#         # Remove July and August from the dataset\n",
    "#         baseline_restr = baseline_df.sel(time=baseline_df.time.dt.month.isin([1, 2, 3, 4, 5, 6, 9, 10, 11, 12]))\n",
    "#     else:\n",
    "#         baseline_restr = baseline_df\n",
    "#     # Create the SCAmask\n",
    "#     # Compute lower and upper SCA values based on confidence interval\n",
    "#     threshold = 70.0\n",
    "#     ci_pct = baseline_restr[ci_var].where(baseline_restr[ci_var] >= threshold)\n",
    "#     ci_pct /= 100.0\n",
    "#     # Mask SCA values where CI is masked\n",
    "#     sca_obs = baseline_restr[sca_var].where(~np.isnan(ci_pct))\n",
    "#     # Maximum SCA value by HRU\n",
    "#     msk_SCAmax = sca_obs.max(axis=0)\n",
    "#     # Number of daily values > 0.0 by HRU\n",
    "#     msk_num_obs = (sca_obs > 0.0).sum(axis=0)\n",
    "#     # Number of years of values by HRU\n",
    "#     msk_num_ann = sca_obs.resample(time='1AS').mean()\n",
    "#     msk_num_ann = (msk_num_ann > 0).sum(axis=0)\n",
    "#     # Create SCA mask based on number of years, SCAmax > 0.5, and total number of observations by HRU\n",
    "#     SCAmask = (msk_num_ann > 1) & (msk_SCAmax > 0.5) & (msk_num_obs > 9)\n",
    "#     # Lower bound of SCA by HRU\n",
    "#     baseline_SCAmin = (ci_pct * sca_obs).where(SCAmask)\n",
    "#     # Upper bound of SCA by HRU\n",
    "#     baseline_SCAmax = (baseline_SCAmin + (1.0 - ci_pct)).where(SCAmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fece70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCA= xr.open_dataset(wkdir / 'baseline_SCA_v11.nc')\n",
    "SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = xr.DataArray(np.zeros(SCA.snow_cover_extent.shape),\n",
    "#                   dims=['time', 'nhru'],\n",
    "#                   coords={'time': SCA.time.data,\n",
    "#                          'nhru': SCA.nhru.data},\n",
    "#                       name='snow_cover_extent_weights')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynhm] *",
   "language": "python",
   "name": "conda-env-pynhm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
