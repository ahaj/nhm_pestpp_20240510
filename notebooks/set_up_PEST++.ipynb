{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeadd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywatershed\n",
    "import pandas as pd\n",
    "from pathlib import Path as pl\n",
    "import json\n",
    "import numpy as np\n",
    "from pywatershed.parameters.prms_parameters import JSONParameterEncoder\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from pest_utils import pars_to_tpl_entries\n",
    "sys.path.append('../dependencies/')\n",
    "import pyemu\n",
    "\n",
    "#import plotly.graph_objects as go\n",
    "#import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653aa2e-8b40-4ee8-bad2-4c828c0d04e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fa6def1",
   "metadata": {},
   "source": [
    "## Functions\n",
    "### Creates a function that writes the parameter file as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_json_tpl(dims, pars, json_filename):\n",
    "    with open(json_filename, \"w\") as ofp:\n",
    "        ofp.write('ptf ~\\n')\n",
    "        json.dump(\n",
    "            {**dims,\n",
    "            **pars},\n",
    "            ofp,\n",
    "            indent=4,\n",
    "            cls=JSONParameterEncoder,\n",
    "        )\n",
    "    # this sucks - should be a more direct way but whatevs. it verks\n",
    "    inlines = open(json_filename, 'r').readlines()\n",
    "    with open(json_filename, 'w') as ofp:\n",
    "        [ofp.write(i.replace('\"~','~').replace('~\"','~')) for i in inlines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14539676",
   "metadata": {},
   "source": [
    "## We will be running on each cutout eventually, but start with one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['01473000','05431486','09112500','14015000']# Create a list of all cutouts\n",
    "#rootdir = pl.Path('../NHM_extractions/20230110_pois_haj/')# Path to location of cutouts\n",
    "\n",
    "exclude_gages = {'01473000':[],\n",
    "                 '05431486':['05431022'],\n",
    "                 '09112500': ['09112200'],\n",
    "                 '14015000': []}\n",
    "                 \n",
    "c_model = all_models[1]\n",
    "wkdir = pl(f'../NHM_extractions/20230110_pois_haj/{c_model}/')\n",
    "c_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4e462",
   "metadata": {},
   "source": [
    "## Read in the oldskool parameter file as nested dictionaries, a.k.a. a Json-style file. This file would need to be written as a .txt file like the original myparam.param, unless Joe changes the pyWatershed code to read in the json-style file instead. Check with Mike/Joe.\n",
    "## Eddie and Andy changed the path for this read to the \"starting values\" that Parker gave us for each extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404cb5ae-47ee-4ac5-b466-be9f7a79675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a87ed-7bf4-4f8f-80c6-13b7acee55d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19bbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "####This was made in a previous notebook now\n",
    "# pardat = pywatershed.parameters.PrmsParameters.load(wkdir / \"myparam.param\")#load parameter file from extraction\n",
    "# pardat.parameters_to_json(wkdir /\"parameters.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b5d82-0086-4eab-ac2b-177d2b4f95d9",
   "metadata": {},
   "source": [
    "## Now the upper portion making the jason and the lower blocks running the model should be completed prior to the output notebook..or in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pardat = pywatershed.parameters.PrmsParameters.load_from_json(wkdir / \"parameters.json\")#load parameter file from extraction\n",
    "pars = pardat.parameters\n",
    "#pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471065b9-90fe-4e5d-a5f7-1e58ffc51b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = pardat.dimensions\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ba664-50cf-4b0f-9d73-976072c9f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check for the pars needed to run NHM model using pyWatershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d289666b-a1ac-4a28-9892-5ff15cef5c01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nhm_processes = [\n",
    "    pywatershed.PRMSSolarGeometry,\n",
    "    pywatershed.PRMSAtmosphere,\n",
    "    pywatershed.PRMSCanopy,\n",
    "    pywatershed.PRMSSnow,\n",
    "    pywatershed.PRMSRunoff,\n",
    "    pywatershed.PRMSSoilzone,\n",
    "    pywatershed.PRMSGroundwater,\n",
    "    pywatershed.PRMSChannel,\n",
    "]\n",
    "\n",
    "nhm_params = []\n",
    "for proc in nhm_processes:\n",
    "    nhm_params += proc.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f85eb-792c-482e-b35c-fd5575661072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nhm_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08980a0",
   "metadata": {},
   "source": [
    "#### View the keys for \"pars\" --These will be the parameters with values listed in the \"myparam_starting_vals.param\" file of the extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5255df8",
   "metadata": {},
   "source": [
    "#### View values of one paramenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars['nhm_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e920a25",
   "metadata": {},
   "source": [
    "## Create a PEST template file version of json-style of myparam_starting_vals.param, \"pars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of hrus from \"pars\"\n",
    "hrus = pars['nhm_id']\n",
    "hrus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs = pars['nhm_seg']\n",
    "segs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955949a",
   "metadata": {},
   "source": [
    "### Run through all the currently-defined parameters, and using Mike's function \"pars_to_tpl_entries()\", write param stating values to a new dataframe \"par_starting_vals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291060d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe with columns parname (pestpp param name) and parval1 (pestpp starting value)\n",
    "par_starting_vals = pd.DataFrame(columns=['parname','parval1', 'parubnd','parlbnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b383006",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_starting_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_starting_vals = pars_to_tpl_entries(pars, 'adjmix_rain', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'carea_max', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'cecn_coef', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'emis_noppt', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'fastcoef_lin', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'freeh2o_cap', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'gwflow_coef', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'jh_coef', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'mann_n', hrus, segs, par_starting_vals, hru_based=False, \n",
    "                    seg_based=True, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'potet_sublim', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'rad_trncf', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'radmax', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'rain_cbh_adj', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'slowcoef_sq', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'smidx_coef', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'smidx_exp', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'snarea_thresh', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'snowinfil_max', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'snow_cbh_adj', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'soil2gw_max', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'soil_moist_max', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'soil_rechr_max_frac', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'ssr2gw_exp', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'ssr2gw_rate', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=False)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'tmax_allrain_offset', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'tmax_allsnow', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'tmax_cbh_adj', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n",
    "par_starting_vals = pars_to_tpl_entries(pars, 'tmin_cbh_adj', hrus, segs, par_starting_vals, hru_based=True, \n",
    "                    seg_based=False, month_based=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23d043-89d5-4d31-b8ed-a75980cd3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_starting_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_starting_vals.set_index('parname', inplace =True, drop = False)\n",
    "par_starting_vals\n",
    "xx = par_starting_vals.loc[par_starting_vals.parname.str.startswith('carea_max'), :]\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51781709-fd13-47fc-853a-238e716305d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a loop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec719bf7-45a4-4ea5-996b-0f2b29582d7a",
   "metadata": {},
   "source": [
    "## Setting bounds for parameters\n",
    "### There were three ways to set parameter bounds in NHM calibration:\n",
    "#### 1) \"not used\" in the by HRU calibration, all HRU values for this type were grouped and moved as a group in the full calibration range for the parameter.\n",
    "#### 2) \"range\" were calibrated by HRU so will move independently within the calibrations range in table 3.\n",
    "#### 2b) \"percent\" were calibrated by HRU but only allowed a range of +/- 20% of the starting value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5469a-d7e0-4530-8f0c-e07974865c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds_path = '../Supporting_information/par_cal_bounds_use.csv'\n",
    "bnds = pd.read_csv(bnds_path) # Creates a data frame of the bounds for par catagories\n",
    "bnds.set_index('parameter_name', inplace =True, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25d337-587d-4500-ac62-fe8bb0ffcbee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bnds.parameter_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355ac75-0ed7-48f9-b0bc-446d337d8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create the lists of parameters for the claibration methods used\n",
    "percent_list = bnds.loc[bnds.HRU_cal_method == 'Percent','parameter_name'].reset_index(drop = True)\n",
    "range_list = bnds.loc[bnds.HRU_cal_method == 'Range','parameter_name']#.to_list() Note, all values are uniform starting values populated from the table 'par_vale_use.csv'\n",
    "not_used_list = bnds.loc[bnds.HRU_cal_method == 'Not used','parameter_name']#.to_list()\n",
    "print(not_used_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6811bec-1baf-4f4e-ae53-43cf51f7f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will rewrite these using the cn, _ and .loc method edicimated to us by 'the great one.'\n",
    "for idx, row in par_starting_vals.iterrows():\n",
    "    for param in percent_list:\n",
    "        pst_parname = str(row.parname)\n",
    "        prms_parname = param\n",
    "        #print(prms_parname)\n",
    "        x = pst_parname.startswith(prms_parname)# Just a yes not response to if the pst parname starts with the root in \"\".\n",
    "        if x:\n",
    "            par_starting_vals.loc[pst_parname,'parubnd'] = (0.2*par_starting_vals.loc[pst_parname, 'parval1'])+par_starting_vals.loc[pst_parname, 'parval1']\n",
    "            par_starting_vals.loc[pst_parname,'parlbnd'] = par_starting_vals.loc[pst_parname, 'parval1']-(0.2*par_starting_vals.loc[pst_parname, 'parval1'])\n",
    "\n",
    "for idx, row in par_starting_vals.iterrows():\n",
    "    for param in range_list:\n",
    "        pst_parname = str(row.parname)\n",
    "        prms_parname = param\n",
    "        #print(prms_parname)\n",
    "        x = pst_parname.startswith(prms_parname)# Just a yes not response to if the pst parname starts with the root in \"\".\n",
    "        if x:\n",
    "             par_starting_vals.loc[pst_parname,'parubnd'] = bnds.loc[prms_parname,'par_upper_bound']\n",
    "             par_starting_vals.loc[pst_parname,'parlbnd'] = bnds.loc[prms_parname,'par_lower_bound']\n",
    "\n",
    "#for idx, row in par_starting_vals.iterrows():\n",
    "#    for param in not_used_list:\n",
    "#        pst_parname = str(row.parname)\n",
    "#        prms_parname = param\n",
    "#        #print(prms_parname)\n",
    "#        x = pst_parname.startswith(prms_parname)# Just a yes not response to if the pst parname starts with the root in \"\".\n",
    "#        if x:\n",
    "#            par_starting_vals.loc[pst_parname,'parubnd'] = (0.2*par_starting_vals.loc[pst_parname, 'parval1'])+par_starting_vals.loc[pst_parname, 'parval1']\n",
    "#            par_starting_vals.loc[pst_parname,'parlbnd'] = par_starting_vals.loc[pst_parname, 'parval1']-(0.2*par_starting_vals.loc[pst_parname, 'parval1'])\n",
    "#             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14713a-f418-4368-bf84-71bce0ff1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xx = par_starting_vals.loc[par_starting_vals.parname.str.startswith('adjmix_rain'), :]\n",
    "#xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f7c65",
   "metadata": {},
   "source": [
    "### once we have all the parameter arrays replaced by names, we can write out the template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012dff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_json_tpl(dims, pars, wkdir / 'parameters.json.tpl')\n",
    "par_starting_vals.to_csv(wkdir / 'starting_par_vals.dat', index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55120f",
   "metadata": {},
   "source": [
    "### Map observation name to the Instruction File (.ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f623d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvals = pd.read_csv(wkdir / 'allobs.dat', delim_whitespace= True)\n",
    "obsvals.set_index('obsname', inplace =True, drop = False)\n",
    "#obsvals.sample(5)\n",
    "print(obsvals)\n",
    "print('The values for \"obsval\" are the true observation values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ed39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wkdir /'modelobs.dat.ins', 'w') as ofp:\n",
    "    ofp.write('pif ~\\n')\n",
    "    ofp.write('~obsval~\\n')\n",
    "    [ofp.write(f'l1 w !{i}!\\n') for i in obsvals.obsname]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacce5df",
   "metadata": {},
   "source": [
    "### create PST control file object with `pyemu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27156d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst.from_io_files(tpl_files = [str(wkdir / 'parameters.json.tpl')],\n",
    "                              in_files=[str(wkdir / 'parameters.json')],# Values for parval1 and bnds will be populated with default values\n",
    "                              ins_files = [str(wkdir / 'modelobs.dat.ins')],\n",
    "                              out_files = [str(wkdir / 'modelobs.dat')], #names the model output file in the control file (prior_mc.pst)--Chk with Mike\n",
    "                              pst_path = '.')\n",
    "#Ask Mike if pyemu reads in the values for the obs from the modelobs.dat file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e1307-f330-40ac-97bf-aca3265c89eb",
   "metadata": {},
   "source": [
    "## Direct editing of the PEST parameter file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa5b6f-1000-44ec-9717-bab6a5315dd4",
   "metadata": {},
   "source": [
    "## Starting parameter values\n",
    "### Starting values were set from the initial parameter file used, in our case it was the \"pre-calibration\" values given to us by Parker. SO! No changes to those values, but we will need to customize the upper and lower bounds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ebfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = pst.parameter_data\n",
    "#pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b3ebed-793d-44c6-952f-e2e2ff997d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74b33a-23df-4811-83b3-ef7fcc1f6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pars.loc['adjmix_rain:hru_5621:mon_1','parval1'] = 987236\n",
    "#pst.parameter_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150b740-62ef-48ae-92e3-147f4b788830",
   "metadata": {},
   "source": [
    "### Copy parval1, upper bound and lower bound from \"par_starting_vals\" to pars.parval1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba15363-bef4-4f11-9c37-12aae0ee2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in pars.iterrows():\n",
    "    pars.loc[pars.parnme,'parval1'] = par_starting_vals.loc[pars.parnme,'parval1']\n",
    "    pars.loc[pars.parnme,'parubnd'] = par_starting_vals.loc[pars.parnme,'parubnd']\n",
    "    pars.loc[pars.parnme,'parlbnd'] = par_starting_vals.loc[pars.parnme,'parlbnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c9dcb-46a0-4d94-9535-ed1391ee7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae181533-d1c2-4760-beac-8d58e5f35c3b",
   "metadata": {},
   "source": [
    "### Copy upper and lower bounds from par_cal_bounds_use.csv to par.parubnd and par.parlbnd\n",
    "### AND...overwite parval1 with new strating values determined from default values listed in PRMS table 5.2.1 (published), https://water.usgs.gov/water-resources/software/PRMS/--Chack with jacob and make sure these jive with what they used in the cal script. NO we are not doing this anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375f48d-e2f7-49bc-9895-268a3758f1c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prms_parnme_list =bnds['parameter_name']# Make a list of the nhm par names for loops below\n",
    "#print(prms_parnme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18793ad5-4d27-4e49-8bcd-f492f68221f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#We recan delete this because we replaced this assignment above\n",
    "#for idx, row in pars.iterrows():\n",
    "#    for i in prms_parnme_list:\n",
    "#        pst_parnme = str(row.parnme)\n",
    "#        prms_parnme = prms_parnme_list[i]\n",
    "#        x = pst_parnme.startswith(prms_parnme)# Just a yes not response to if the pst parname starts with the root in \"\".\n",
    "#        if x :\n",
    "#            pars.loc[pst_parnme,'parubnd'] = bnds.loc[prms_parnme,'par_upper_bound']\n",
    "#            pars.loc[pst_parnme,'parlbnd'] = bnds.loc[prms_parnme,'par_lower_bound']\n",
    "#            #pars.loc[pst_parnme,'parval1'] = bnds.loc[prms_parnme,'par_start_val'] remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12b45f-de06-460b-9712-ead106ff4f8e",
   "metadata": {},
   "source": [
    "### we can't log transform negative parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bf124-4059-4e2b-b31f-7f6ad8605cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.parlbnd<=0, 'partrans'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a99da-330a-46a7-98c7-e68f8f3588fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### obs.loc[obsvals.obsname, 'obsval'] = obsvals.obsval.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb27eb-a6d9-4119-8d83-03a3f6e0df44",
   "metadata": {},
   "source": [
    "#### Set obsval in the \"pst.observation_data\" frame back to the true observation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05937510",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data #This pulls the \"observation data\" from the pst dataframe and sets it to the \"obs\" object (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595366f-0973-4c41-967a-727ddc04fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obsnme, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36666ac-d87c-47da-bd13-85abe776ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obsnme =='actet_mon:2000_1:5621',:] # This is the value in the modelobs.dat file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0ceea-f2a4-45dc-aa45-c29e515e032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvals.loc[obsvals.obsname =='actet_mon:2000_1:5621',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed908fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs = obs.loc[obsvals.obsname,:] #resorts datframe for easy in reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63643eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obsvals.obsname, 'obsval'] = obsvals.obsval.values #True observation value is copied over to obs\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012bdec-fd5a-4d20-8e26-cb01e5bd5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obsnme =='actet_mon:2000_1:5621',:] # Check for change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912214d",
   "metadata": {},
   "source": [
    "#### Creating Groups observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obsnme.str.startswith('l_max_actet_mon'),'obgnme'] = 'l_max_actet_mon'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_actet_mon'),'obgnme'] = 'g_min_actet_mon'\n",
    "\n",
    "obs.loc[obs.obsnme.str.startswith('l_max_actet_mean_mon'),'obgnme'] = 'l_max_actet_mean_mon'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_actet_mean_mon'),'obgnme'] = 'g_min_actet_mean_mon'\n",
    "\n",
    "obs.loc[obs.obsnme.str.startswith('l_max_recharge_ann'),'obgnme'] = 'l_max_recharge_ann'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_recharge_ann'),'obgnme'] = 'g_min_recharge_ann'\n",
    "\n",
    "obs.loc[obs.obsnme.str.startswith('l_max_soil_moist_mon'),'obgnme'] = 'l_max_soil_moist_mon'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_soil_moist_mon'),'obgnme'] = 'g_min_soil_moist_mon'\n",
    "\n",
    "obs.loc[obs.obsnme.str.startswith('l_max_soil_moist_ann'),'obgnme'] = 'l_max_soil_moist_ann'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_soil_moist_ann'),'obgnme'] = 'g_min_soil_moist_ann'\n",
    "\n",
    "\n",
    "#obs.loc[obs.obsnme.str.startswith('runoff_mon'),'obgnme'] = 'runoff_mon'\n",
    "obs.loc[obs.obsnme.str.startswith('l_max_runoff_mon'),'obgnme'] = 'l_max_runoff_mon'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_runoff_mon'),'obgnme'] = 'g_min_runoff_mon'\n",
    "\n",
    "#obs.loc[obs.obsnme.str.startswith('sca_daily'),'obgnme'] = 'sca_daily'\n",
    "obs.loc[obs.obsnme.str.startswith('l_max_sca_daily'),'obgnme'] = 'l_max_sca_daily'\n",
    "obs.loc[obs.obsnme.str.startswith('g_min_sca_daily'),'obgnme'] = 'g_min_sca_daily'\n",
    "\n",
    "\n",
    "\n",
    "#obs.loc[obs.obsnme.str.startswith('streamflow_daily'),'obgnme'] = 'streamflow_daily'\n",
    "\n",
    "# Create EFC Groups for daily streamflows\n",
    "# streamflow_daily is followed by a suffix: \"efc\"_\"high_low\" integers\n",
    "# efc [1, 2, 3, 4, 5] are ['Large flood', 'Small flood', 'High flow pulse', 'Low flow', 'Extreme low flow']\n",
    "# high_low [1, 2, 3] are ['Low flow', 'Ascending limb', 'Descending limb']\n",
    "# Pest++ group names were written with flows in mind.\n",
    "\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_1_2'),'obgnme'] = 'streamflow_daily_large_asc'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_1_3'),'obgnme'] = 'streamflow_daily_large_dsc'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_2_2'),'obgnme'] = 'streamflow_daily_small_asc'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_2_3'),'obgnme'] = 'streamflow_daily_small_dsc'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_3_2'),'obgnme'] = 'streamflow_daily_pulse_asc'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_3_3'),'obgnme'] = 'streamflow_daily_pulse_dsc'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_4_1'),'obgnme'] = 'streamflow_daily_low'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_5_1'),'obgnme'] = 'streamflow_daily_exlow'\n",
    "\n",
    "#Special group for no flow\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_daily_-9999_-9999'),'obgnme'] = 'streamflow_nodata'\n",
    "obs.loc[(obs.obsnme.str.startswith('streamflow_daily')) &\n",
    "      (obs.obsval==-9999), 'obgnme'] = 'streamflow_nodata'\n",
    "for ex in exclude_gages[c_model]:\n",
    "    obs.loc[(obs.obsnme.str.startswith('streamflow_daily')) &\n",
    "      (obs.obsnme.str.endswith(ex)), 'obgnme'] = 'streamflow_nodata'\n",
    "\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_mon'),'obgnme'] = 'streamflow_mon'\n",
    "obs.loc[obs.obsnme.str.startswith('streamflow_mean_mon'),'obgnme'] = 'streamflow_mean_mon'\n",
    "obs.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901a06e-a546-4c2b-be14-9396fa2327ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs.loc[obs['obgnme']=='streamflow_nodata'].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920553ad-4d27-4365-9d16-1773cc1db075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13ddfa-ab4e-4d2a-a886-b50143e0eb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e078f7-bcde-441b-ae9c-033b66163383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Set weights for groups\"\n",
    "## TODO: Assign weights for all but streamflow that make sense as 1/std\n",
    "\n",
    "###Need to tailor these wts individually to the STDV values that we assume are \"good.\"\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_actet_mean_mon','weight'] = 3.0E+04\n",
    "# obs.loc[obs.obgnme=='g_min_actet_mean_mon','weight'] = 3.0E+04\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_actet_mon','weight'] = 0.75E+04\n",
    "# obs.loc[obs.obgnme=='g_min_actet_mon','weight'] = 0.75E+04\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_recharge_ann','weight'] = 0.4E+04\n",
    "# obs.loc[obs.obgnme=='g_min_recharge_ann','weight'] = 0.4E+04\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_soil_moist_ann','weight'] = 2.5E+03\n",
    "# obs.loc[obs.obgnme=='g_min_soil_moist_ann','weight'] = 2.5E+03\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_soil_moist_mon','weight'] = 8E+02\n",
    "# obs.loc[obs.obgnme=='g_min_soil_moist_mon','weight'] = 8E+02\n",
    "\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_sca_daily','weight'] = 0 #3E-03\n",
    "# obs.loc[obs.obgnme=='g_min_sca_daily','weight'] = 0 #3E-03\n",
    "\n",
    "# obs.loc[obs.obgnme=='l_max_runoff_mon','weight'] = 3.5\n",
    "# obs.loc[obs.obgnme=='g_min_runoff_mon','weight'] = 3.5\n",
    "\n",
    "\n",
    "\n",
    "# obs.loc[obs.obgnme.str.startswith('streamflow'), 'weight'] = \\\n",
    "#     10 / obs.loc[obs.obgnme.str.startswith('streamflow'),'obsval']\n",
    "# obs.loc[obs.obgnme=='streamflow_nodata','weight'] = 0\n",
    "\n",
    "# # special case for streamflow with 0 observed value\n",
    "# obs.loc[(obs.obsval<=1) & (obs.obgnme.str.startswith('stream')), 'weight'] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3d640-7cf2-46ca-a31a-28304d069eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[(obs.obsval<=1) & (obs.obgnme.str.startswith('stream'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41142f-441f-49ff-bc37-7594555f2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs.loc[obs.obgnme.str.startswith('streamflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafe639-d358-4d56-9a77-35955bcb49ec",
   "metadata": {},
   "source": [
    "## now we flip these weights back to standard deviation for the noise ensemble and then do not revisit STD, although we will adjust weights to rebalance PHI--Retooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50317746-11c3-4a11-9a25-7af4e7bd0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs.loc[:,'standard_deviation'] = [1/w if w!=0 else 1e-6 for w in obs.weight]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a225bda-d595-4408-81be-82c187600eb3",
   "metadata": {},
   "source": [
    "## Set SD and bounds for obs from file \"Observation_standard_deviation.csv\" in Supporting Information folder; if you want to change bounds and SD, change values in the .csv file. Primarily to make sure values during the prior don't go negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32e6a8-afa3-4ff3-8976-ad17c04c8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_sdbnds_path = '../Supporting_information/Observation_standard_deviation.csv'\n",
    "obs_sdbnds = pd.read_csv(obs_sdbnds_path) # Creates a data frame of the bounds for par catagories\n",
    "obs_sdbnds.set_index('obsgroup', inplace =True, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37859fc7-1420-4b1b-9d06-6ba9ed115c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_sdbnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f59fc-3367-4f37-9679-f751921aa274",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_sdbnds.index =[i.strip() for i in obs_sdbnds.index]# strip removes the extra spaces and /n etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1fa481-f874-4b46-9377-378945c2bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_sdbnds.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8aa1d7-d89a-495a-87a6-78cce83737eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['lower_bound'] = 0\n",
    "obs['upper_bound'] = np.nan\n",
    "obs['standard_deviation'] = np.nan\n",
    "#obs['weight'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494aec2-e3d6-4397-82f3-4bc963b00f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsgroup_list = obs_sdbnds['obsgroup']\n",
    "obsgroup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636d705-2389-4ae8-9456-4008508d26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_sdbnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0685bc-cdeb-46c8-baa4-21bef3dfe544",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obgnme=='streamflow_nodata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff95b7a-cdb2-4aeb-9148-5e18f74a7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadf4a8-f724-42b0-a217-21518821939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cn,_ in obs.groupby('obgnme'):\n",
    "    obs.loc[obs.obgnme == cn, 'upper_bound']= obs_sdbnds.loc[cn, 'obsubnd']\n",
    "    #print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f57f7c-bdbb-4b91-9c81-3a2f10a6a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cn,_ in obs.groupby('obgnme'):\n",
    "    obs_group_percent = obs_sdbnds.loc[cn, 'noise_percent']\n",
    "    obs.loc[obs.obgnme == cn, 'standard_deviation']= obs_group_percent*(obs.loc[obs.obgnme==cn, 'obsval'])\n",
    "    #print(cn)\n",
    "\n",
    "#Replace std value with 9999 where obsval values with \"9999\"\n",
    "obs.loc[obs.obsval == -9999, 'standard_deviation']= 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f3738-226e-494a-b8fa-2affa2d24fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs.loc[obs.standard_deviation.isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66503f1f-f741-4a81-b405-0b8a1687b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But, to read in the \"other\" SD, the SD for the value, not the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd53ba-5028-444e-8268-55f2fbc71cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Do this for streamflow but not the rest\n",
    "for cn,_ in obs.groupby('obgnme'):\n",
    "    if cn.startswith('streamflow_'):\n",
    "        obs_group_percent = obs_sdbnds.loc[cn, 'wt_percent']#\"wt_percent\" in th etable is a fractional value from csv\n",
    "        obs.loc[obs.obgnme == cn, 'weight']= 1/(obs_group_percent*(obs.loc[obs.obgnme==cn, 'obsval']))\n",
    "    else:\n",
    "        obs_group_percent = obs_sdbnds.loc[cn, 'wt_percent']\n",
    "        obs.loc[obs.obgnme == cn, 'weight']= 1/obs_group_percent\n",
    "\n",
    "\n",
    "#For the inequality calibration obs, do NOT take weight calc using the obs val\n",
    "obs.loc[obs.obgnme.str.startswith('streamflow_'),'weight'] = 'streamflow_daily_large_asc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af746dfe-d2bf-41ec-87f1-110fa7d53b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obgnme=='l_max_sca_daily','weight'] = 10#3E-03\n",
    "obs.loc[obs.obgnme=='g_min_sca_daily','weight'] = 10#3E-00\n",
    "\n",
    "obs.loc[obs.obgnme.str.startswith('streamflow'), 'weight'] = \\\n",
    "    10 / obs.loc[obs.obgnme.str.startswith('streamflow'),'obsval']\n",
    "\n",
    "obs.loc[obs.obgnme=='streamflow_nodata','weight'] = 0\n",
    "\n",
    "# special case for streamflow with 0 observed value\n",
    "obs.loc[(obs.obsval<=1) & (obs.obgnme.str.startswith('stream')), 'weight'] = 1.0\n",
    "\n",
    "#Replace -9999 obs_val values with 0 weight\n",
    "obs.loc[obs.obsval == -9999, 'weight']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d89b1f-540e-4551-a55b-3460d15f2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5d36c-8cda-4acd-bafd-5a9114bae7f5",
   "metadata": {},
   "source": [
    "# consolidate the run scripts into a single script\n",
    "### Eddie commented out after modification of the forward_run.py file with James during debugging. Eddie will eventually fix this and bring it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac37b40-28c7-48e2-825a-7b61ae2a6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imports = [i.strip() for i in open('../scripts/run-pynhm.py', 'r').readlines() if i.strip().startswith('import')]\n",
    "imports.extend([i.strip() for i in open('../scripts/post-process_model_output.py', 'r').readlines() if i.strip().startswith('import')])\n",
    "\n",
    "runbiz = [i.rstrip() for i in open('../scripts/run-pynhm.py', 'r').readlines() if not i.strip().startswith('import')]\n",
    "runbiz.append('print(\"#### RUN DONE, TIME TO POSTPROCESS ####\")')\n",
    "runbiz.extend([i.rstrip() for i in open('../scripts/post-process_model_output.py', 'r').readlines() if not i.strip().startswith('import')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174858ba-16ee-40ed-a566-61c0ef3b78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runbiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d275cd-89c8-4b56-9b30-666920aa6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedupe the imports\n",
    "imports = list(set(imports))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d9b0d-b512-4ee5-950f-39325d683c9a",
   "metadata": {},
   "source": [
    "### now write out all the forward run stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c16cb5-15f8-462b-9881-cae24ac64d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wkdir / 'forward_run.py', 'w') as ofp:\n",
    "    [ofp.write(f'{line}\\n') for line in imports+runbiz]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfd9a4-60b2-4898-b46d-c76336ee6766",
   "metadata": {},
   "source": [
    "### and set the consolidated forward_run.py file to the pst object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b07cd-4d9d-4092-980a-bca985796f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.model_command = ['python forward_run.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8358e4-b580-45ed-a02b-dc8918c73dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax=0 #or -1 later, 0 at first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9c927-7789-40d9-ac15-864aaf3f4770",
   "metadata": {},
   "source": [
    "### set some PEST++ specific parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af53650-a76e-46f5-8a85-fc37e2fb6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"ies_num_reals\"] = 500  \n",
    "\n",
    "pst.pestpp_options[\"ies_bad_phi_sigma\"] = 2.5\n",
    "pst.pestpp_options[\"overdue_giveup_fac\"] = 4\n",
    "pst.pestpp_options[\"ies_no_noise\"] = False\n",
    "pst.pestpp_options[\"ies_drop_conflicts\"] = False\n",
    "pst.pestpp_options[\"ies_pdc_sigma_distance\"] = 3.0\n",
    "pst.pestpp_options['ies_autoadaloc']=False\n",
    "pst.pestpp_options['ies_num_threads']=4\n",
    "pst.pestpp_options['ies_lambda_mults']=(0.1,1.0,10.0,100.0)\n",
    "pst.pestpp_options['lambda_scale_fac'] = (0.75,0.9,1.0,1.1)\n",
    "pst.pestpp_options['ies_subset_size']=10\n",
    "\n",
    "# set SVD for some regularization\n",
    "pst.svd_data.maxsing = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acade9-18d0-41c1-bb85-a9bc786346b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pst.observation_data.loc[pst.observation_data.weight==0]) >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05699047-0641-4882-afeb-53eaae5be8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data=pst.parameter_data[['parnme','partrans',\t'parchglim', 'parval1',\t'parlbnd', 'parubnd','pargp','scale', 'offset', 'dercom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5735c2d3-72e0-4342-9ef6-e49b64d93053",
   "metadata": {},
   "source": [
    "### special case for just this one value with busted bounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ded886-b566-451c-8c81-f9264d28b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pst.parameter_data.loc['smidx_exp:hru_84017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9df11-b1b3-4df0-a9cb-d5991fd84dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'smidx_exp:hru_84017' in pst.parameter_data.index:\n",
    "    pst.parameter_data.loc['smidx_exp:hru_84017', 'parval1'] = 0.003\n",
    "    pst.parameter_data.loc['smidx_exp:hru_84017', 'parubnd'] = .003*2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(str(wkdir / 'prior_mc.pst'), version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5aa21b-aff8-4c66-b9d0-c507a28f7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[pst.observation_data[i].isnull().unique() for i in pst.observation_data.columns]\n",
    "obs.loc[obs.weight.isnull()].obgnme.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be986e2-3df3-4e15-affb-cb4529274f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f801e16-e2e3-40d2-8c67-dec5fb982269",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pst.observation_data), len(pst.observation_data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d19e8-485c-47eb-80fe-74c76e2f7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[list(set(pst.observation_data.index) - set(pst.observation_data.dropna().index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc96b18-7a25-4084-9b2a-224daf7288b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[(pst.observation_data.obgnme=='streamflow_daily_exlow') &\n",
    "(pst.observation_data.obsval==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7fdb7f-7807-4353-81d6-87371bff7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[(pst.observation_data.obsnme=='streamflow_daily_3_2:2000_7_11:05431022')] #&\n",
    "#(pst.observation_data.weight>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea9a22-eea8-4078-821a-a4759eee9300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133d004-3eed-4baf-8ca5-a4b6a39d5af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcf0c8-90f0-4b1a-8461-b60ee705c67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
