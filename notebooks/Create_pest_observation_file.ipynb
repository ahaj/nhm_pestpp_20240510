{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80947fdb",
   "metadata": {},
   "source": [
    "### This notebook will read in the consolidated NC files that were written with notebook  `Subset_NHM_baselines`for each subbasin extraction, assign names for each obs, and write names and observations into a single file with 2 columns for PEST++ to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf95cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywatershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461b850",
   "metadata": {},
   "source": [
    "### Designate the list on subabsin extractions and the root directory that contains them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759528db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['01473000', '05431486','09112500','14015000']# Used later when automating loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = pl.Path('../NHM_extractions/20230110_pois_haj/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b0b6e",
   "metadata": {},
   "source": [
    "### For now, working for now in a single subasin extraction and will automate later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13700147",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = all_models[3]\n",
    "obsdir = rootdir/ cm / 'observation_data'#This is where the observation files for each extraction were written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nc_files = sorted([i for i in (rootdir/ cm / 'observation_data').glob('*.nc')])#Read in the files to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac33304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_nc_files #Checks all the subset observation files from the CONUS NHM outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file to hold the consolidated results\n",
    "ofp = open(rootdir / cm / 'allobs.dat', 'w') # the 'w' will delete any existing file here and recreate; 'a' appends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  AET  monthly (Note that these values are in inches/day, and a daily average rate for the month--Jacob verified)\n",
    "cdat  = xr.open_dataset(obsdir / 'AET_monthly.nc')\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i.year}_{i.month}:{j}' for i in cdat.indexes['time'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "#aet_monthly_obs = (cdat.aet_max + cdat.aet_min)/2#calculates mean value using aet_max and aet_min\n",
    "#varvals =  np.ravel(aet_monthly_obs, order = 'C')# flattens the 2D array to a 1D array \n",
    "\n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#    ofp.write('obsname    obsval\\n') # writing a header for the file\n",
    "#    [ofp.write(f'actet_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "#sets the non-penalized condition to less than the max value\n",
    "l_max_actet_mon = cdat.aet_max\n",
    "varvals =  np.ravel(l_max_actet_mon, order = 'C')# flattens the 2D array to a 1D array \n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    ofp.write('obsname    obsval\\n') # writing a header for the file\n",
    "    [ofp.write(f'l_max_actet_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "#sets the non-penalized condition to greater than the min value\n",
    "g_min_actet_mon = cdat.aet_min\n",
    "varvals =  np.ravel(g_min_actet_mon, order = 'C')# flattens the 2D array to a 1D array \n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'g_min_actet_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1930b9-60c8-460d-8e2a-17df995442cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aet_mean_obs\n",
    "#aet_monthly_obs.sel(time= '2000-01-01') # look at a slice of the netcdf and compare to pest write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  AET mean monthly\n",
    "cdat  = xr.open_dataset(obsdir / 'AET_mean_monthly.nc')\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i}:{j}' for i in cdat.indexes['month'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "#aet_mean_obs = (cdat.aet_min + cdat.aet_max)/2#calculates mean value using aet_max and aet_min\n",
    "#varvals =  np.ravel(aet_mean_obs, order = 'C')# flattens the 2D array to a 1D array \n",
    "\n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#    [ofp.write(f'actet_mean_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "l_max_actet_mean_mon = cdat.aet_max\n",
    "varvals =  np.ravel(l_max_actet_mean_mon, order = 'C')# flattens the 2D array to a 1D array \n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'l_max_actet_mean_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "#sets the non-penalized condition to greater than the min value\n",
    "g_min_actet_mean_mon = cdat.aet_min\n",
    "varvals =  np.ravel(g_min_actet_mean_mon, order = 'C')# flattens the 2D array to a 1D array \n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'g_min_actet_mean_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c18dcf-0d63-402c-a1fe-185ab63ea3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aet_mean_obs.sel(month= 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  RCH  annual\n",
    "cdat  = xr.open_dataset(obsdir / 'RCH_annual.nc')\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i.year}:{j}' for i in cdat.indexes['time'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "# get the variable names\n",
    "#dvs = list(cdat.keys())\n",
    "#recharge_mean_obs = (cdat.recharge_max_norm + cdat.recharge_min_norm)/2#calculates mean value using aet_max and aet_min\n",
    "\n",
    "#varvals =  np.ravel(recharge_mean_obs, order = 'C')# flattens the 2D array to a 1D array \n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#    [ofp.write(f'recharge_ann:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "l_max_recharge_ann = cdat.recharge_max_norm\n",
    "varvals =  np.ravel(l_max_recharge_ann, order = 'C')# flattens the 2D array to a 1D array \n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'l_max_recharge_ann:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "g_min_recharge_ann = cdat.recharge_min_norm\n",
    "varvals =  np.ravel(g_min_recharge_ann, order = 'C')# flattens the 2D array to a 1D array \n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'g_min_recharge_ann:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97fd54-1b3d-40b6-9bc1-9440497a43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recharge_mean_obs.sel(time='2000-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Soil Moisture  monthly\n",
    "cdat  = xr.open_dataset(obsdir / 'Soil_Moisture_monthly.nc')\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i.year}_{i.month}:{j}' for i in cdat.indexes['time'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "# get the variable names\n",
    "#dvs = list(cdat.keys())\n",
    "#soil_moist_mean_obs = (cdat.soil_moist_max_norm + cdat.soil_moist_min_norm)/2#calculates mean value using aet_max and aet_min\n",
    "\n",
    "#varvals =  np.ravel(soil_moist_mean_obs, order = 'C')# flattens the 2D array to a 1D array\n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#    [ofp.write(f'soil_moist_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "l_max_soil_moist_mon = cdat.soil_moist_max_norm\n",
    "varvals =  np.ravel(l_max_soil_moist_mon, order = 'C')# flattens the 2D array to a 1D array\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'l_max_soil_moist_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "g_min_soil_moist_mon = cdat.soil_moist_min_norm\n",
    "varvals =  np.ravel(g_min_soil_moist_mon, order = 'C')# flattens the 2D array to a 1D array\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'g_min_soil_moist_mon:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f22339-01ac-4e71-b92f-b8e1a24c90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soil_moist_mean_obs.sel(time='1982-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabefe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Soil_Moisture annual\n",
    "cdat  = xr.open_dataset(obsdir / 'Soil_Moisture_annual.nc')\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i.year}:{j}' for i in cdat.indexes['time'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "# get the variable names\n",
    "#dvs = list(cdat.keys())\n",
    "\n",
    "#soil_moist_mean_obs = (cdat.soil_moist_max_norm + cdat.soil_moist_min_norm)/2#calculates mean value using aet_max and aet_min\n",
    "\n",
    "#varvals =  np.ravel(soil_moist_mean_obs, order = 'C')# flattens the 2D array to a 1D array\n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#    [ofp.write(f'soil_moist_ann:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "l_max_soil_moist_ann = cdat.soil_moist_max_norm \n",
    "varvals =  np.ravel(l_max_soil_moist_ann, order = 'C')# flattens the 2D array to a 1D array\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'l_max_soil_moist_ann:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n",
    "g_min_soil_moist_ann = cdat.soil_moist_min_norm \n",
    "varvals =  np.ravel(g_min_soil_moist_ann, order = 'C')# flattens the 2D array to a 1D array\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'g_min_soil_moist_ann:{i}          {j}\\n') for i,j in zip(inds,varvals, strict=True)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057063c-6f04-4c20-b055-f5c8266b693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soil_moist_mean_obs.sel(time='1982-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8824478-c3bd-4dc0-9f7f-51eed26cc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  RUN  monthly (This is an average daily rate in cfs for the month)\n",
    "cdat  = xr.open_dataset(obsdir / 'hru_streamflow_monthly.nc')\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i.year}_{i.month}:{j}' for i in cdat.indexes['time'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "# get the variable names\n",
    "#varvals =  np.ravel(cdat.runoff_mwbm, order = 'C')# flattens the 2D array to a 1D array\n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#    [ofp.write(f'runoff_mon:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]\n",
    "\n",
    "l_max_runoff_mon = cdat.runoff_max \n",
    "varvals =  np.ravel(l_max_runoff_mon, order = 'C')# flattens the 2D array to a 1D array\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'l_max_runoff_mon:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]\n",
    "\n",
    "g_min_runoff_mon = cdat.runoff_min \n",
    "varvals =  np.ravel(g_min_runoff_mon, order = 'C')# flattens the 2D array to a 1D array\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'g_min_runoff_mon:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250248e0-0651-4719-a281-a7574da12b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdat.runoff_mwbm.sel(time='1982-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58051a68",
   "metadata": {},
   "source": [
    "## the following has NaNs for SCA daily that got rejected by the filter. Need to decide if totally drop, or give a dummary value (-999) or whatnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Snow_covered_area daily\n",
    "cdat  = xr.open_dataset(obsdir / 'SCA_daily.nc')\n",
    "cdat = cdat.fillna(-9999)\n",
    "# set up the indices in sequence\n",
    "inds = [f'{i.year}_{i.month}_{i.day}:{j}' for i in cdat.indexes['time'] for j in cdat.indexes['nhru']]\n",
    "\n",
    "# get the variable names\n",
    "#dvs = list(cdat.keys())\n",
    "\n",
    "#SCA_mean_obs = (cdat.SCA_max + cdat.SCA_min)/2#calculates mean value using aet_max and aet_min\n",
    "#varvals =  np.ravel(SCA_mean_obs, order = 'C')# flattens the 2D array to a 1D array\n",
    "#\n",
    "#with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "#            [ofp.write(f'sca_daily:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]\n",
    "\n",
    "l_max_sca_daily = cdat.SCA_max\n",
    "varvals =  np.ravel(l_max_sca_daily, order = 'C')# flattens the 2D array to a 1D array\n",
    "\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "            [ofp.write(f'l_max_sca_daily:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]\n",
    "    \n",
    "g_min_sca_daily = cdat.SCA_min\n",
    "varvals =  np.ravel(g_min_sca_daily, order = 'C')# flattens the 2D array to a 1D array\n",
    "\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "            [ofp.write(f'g_min_sca_daily:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a33a9-97fa-4104-8e00-f6d436707f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCA_mean_obs.sel(time='2000-02-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Streamflow daily\n",
    "###### Warning: You must run the EFC notebook prior to this block to create the new sf file with EFC codes \"EFC_netcdf\"\n",
    "seg_outflow_start = '2000-01-01'# Note: For ease, the start and end dates must be same as those designated in\n",
    "seg_outflow_end = '2010-12-31'#    \"the Create_pest_model_observation_file.\"\n",
    "\n",
    "cdat  = xr.open_dataset(rootdir/ cm / 'sf_data_with_EFC.nc').sel(time=slice(seg_outflow_start, seg_outflow_end))\n",
    "cdat = cdat[['discharge', 'efc', 'high_low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e7abb-f5a8-4cda-b342-da61dffde508",
   "metadata": {},
   "outputs": [],
   "source": [
    "moo = cdat.discharge.to_dataframe()\n",
    "moo.loc[moo['discharge'] <0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cff73d-9e37-4907-aa2f-6f4237b10334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dataframe time series of monthly values (average daily rate for the month)\n",
    "cdat_monthly = cdat.resample(time = 'm').mean(skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106e4b2-2429-4dfe-b7ec-224ce13c80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe time series of mean monthly (mean of all jan, feb, mar....)\n",
    "cdat_mean_monthly = cdat_monthly.groupby('time.month').mean(skipna=True)\n",
    "\n",
    "cdat_mean_monthly = cdat_mean_monthly.fillna(-9999)\n",
    "cdat_monthly = cdat_monthly.fillna(-9999)\n",
    "cdat = cdat.fillna(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e89dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamflow_daily is followed by a suffix: \"efc\"_\"high_low\" integers\n",
    "# efc [1, 2, 3, 4, 5] are ['Large flood', 'Small flood', 'High flow pulse', 'Low flow', 'Extreme low flow']\n",
    "# high_low [1, 2, 3] are ['Low flow', 'Ascending limb', 'Descending limb']\n",
    "\n",
    "# set up the indices in sequence\n",
    "inds = [f'_{int(cdat[\"efc\"].sel(poi_id=j, time=i).item())}_{int(cdat[\"high_low\"].sel(poi_id=j, time=i).item())}:{i.year}_{i.month}_{i.day}:{j}' for j in cdat.indexes['poi_id'] for i in cdat.indexes['time']]\n",
    "\n",
    "# get the variable names\n",
    "#dvs = list(cdat.keys())\n",
    "\n",
    "varvals =  np.ravel(cdat['discharge'], order = 'C')# flattens the 2D array to a 1D array\n",
    "\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "            [ofp.write(f'streamflow_daily{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d6884-c360-447f-9eb9-2fc0df754811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now write to the pest obs file\n",
    "inds = [f'{i.year}_{i.month}:{j}' for j in cdat_monthly.indexes['poi_id'] for i in cdat_monthly.indexes['time'] ]# set up the indices in sequence\n",
    "varvals = np.ravel(cdat_monthly['discharge'], order = 'F')# flattens the 2D array to a 1D array--just playing \n",
    "\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'streamflow_mon:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dafd2-ad9e-4459-ac05-40a36eafb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = [f'{i}:{j}' for j in cdat_mean_monthly.indexes['poi_id'] for i in cdat_mean_monthly.indexes['month'] ]\n",
    "varvals =  np.ravel(cdat_mean_monthly['discharge'], order = 'F')# flattens the 2D array to a 1D array \n",
    "\n",
    "with open(rootdir / cm / 'allobs.dat', encoding=\"utf-8\", mode='a') as ofp:\n",
    "    [ofp.write(f'streamflow_mean_mon:{i}          {j}\\n') for i,j in zip(inds,varvals,strict=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b028e31-211f-423c-b0ce-f46c7cfb4c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
